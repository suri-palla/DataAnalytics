# R-Sript to fetech Restaurants Reviews #

# ----- Library Calls ------------------------------------------
library(rvest)
library("XML")

# ------ Configurations--------------------------------------------------------------------------------
# Enter the file name(unique_businesses.txt) here that has unique business id,name,url and review count
# The file is generated by the API program "Build_Business_Master_List.R"

filename <- "UNIQUE_BUSINESSES_FILE.txt"


# ----- Initializations ----------------------------------------
rm(backup.write)
rm(backup.write.temp)
dummy = ""
rest.name <- ""
rest.reviews <- as.list("")
restaurant.cat <- ""
rest.review.count <- ""
rest.bus.url <- ""
backup.write <- c()
#------------------------------------

#------------------------------------
#          Functions 
#------------------------------------


#-----------------------START--------------------------------------------
# -----FETECH SPAM REVIEWS AND OTHER FIELDS FROM YELP WEBSITE------------
#------------------------------------------------------------------------


processSpamReviewContainers <- function(review.containers,rest.id,list.index) {
  
  
  
  #-------------------------------------------------------------
  #-- list.review will have the count of total number of reviews
  #-- reviews will have all the reviews from the yelp website 
  #-------------------------------------------------------------
  
  #   list.index <- 0
  
  reviews <- list()
  
  
  for (i in 1:length(review.containers)) {
    
    
    previous.review.div <- ""
    
    
    time.review.unique.id <- ""
    time.review.date <- ""
    time.review.date <- as.Date(c("0/00/0000"),"%m/%d/%Y")
    
    
    #----------------------------------------------------------------------------
    # this is main loop which process all the reviews on a single yelp webpage
    #
    # each entry of review.containers corresponds to the xpath of a single review 
    # each "review container" will have one "review sidebar" div
    # take care of the "review sidebar" div here
    # ---------------------------------------------------------------------------
    review.containers.unique.id <- html_attr(review.containers[i],name = "data-review-id")
    review.sidebar <- html_nodes(review.containers[[i]], xpath = "div[@class='review-sidebar']")
    review.sidebar.content <- html_nodes(review.sidebar, xpath = "div[@class='review-sidebar-content']")
    review.ypassport.media.block <- html_nodes(review.sidebar.content, xpath = "div[@class='ypassport media-block']")
    review.media.story <- html_node(review.ypassport.media.block, xpath = "div[@class='media-story']")
    
    #     review.user.name.node <- tryCatch(html_node(review.media.story,xpath = ".//li/a[@class='user-display-name']"),
    #                                       error = function(err){return(err)})
    review.user.name.node <- tryCatch(html_node(review.media.story,xpath = ".//li/a[@class='user-display-name']"),
                                      error = function(err){return(err)})
    
    if(class(review.user.name.node)[1] == "xml_nodeset" )
    {
      review.user.name <- html_text(review.user.name.node)
    } else {
      
      review.user.name.node.t1 <- html_node(review.media.story,xpath = ".//li[@class='user-name']")
      
      review.user.name <- html_text(review.user.name.node.t1,trim = T)
      
    }
    
    #     review.user.location.node <- html_node(review.media.story,xpath = ".//li[@class='user-location']")
    review.user.location.node <- html_node(review.media.story,xpath = ".//li[@class='user-location responsive-hidden-small']")
    review.user.location <- html_text(review.user.location.node, trim = T)
    review.user.friends.node.t1 <- html_node(review.media.story,xpath = ".//li[@class='friend-count responsive-small-display-inline-block']")
    # review.user.friends.node.t2 <- html_node(review.user.friends.node.t1,xpath = ".//span[@class='i-wrap ig-wrap-common_sprite i-18x18_friends_c-common_sprite-wrap']")
    review.user.friends.node.t3 <- html_node(review.user.friends.node.t1,xpath = ".//b")
    review.user.friends <- html_text(review.user.friends.node.t3)
    review.user.reviews.node.t1 <- html_node(review.media.story,xpath = ".//li[@class='review-count responsive-small-display-inline-block']")
    # review.user.reviews.node.t2 <- html_node(review.user.reviews.node.t1,xpath = ".//span[@class='i-wrap ig-wrap-common_sprite i-18x18_review_c-common_sprite-wrap']")
    review.user.reviews.node.t3 <- html_node(review.user.reviews.node.t1,xpath = ".//b")
    review.user.reviews <- html_text(review.user.reviews.node.t3)
    review.user.elite.node <- tryCatch(html_node(review.media.story,xpath =".//li[@class='is-elite responsive-small-display-inline-block']"),
                                       error = function(err){return(err)})
    if(class(review.user.elite.node)[1] == "xml_nodeset" )
    {         
      review.user.elite.t1 <- html_text(review.user.elite.node)
      review.user.elite <- trimws(gsub("\n","",review.user.elite.t1))
    } else {
      
      review.user.elite <- "NA"
    }     
    #     
    #             review.user.name
    #             
    #             review.user.location
    #             
    #             review.user.friends
    #             
    #             review.user.reviews
    #         
    #     
    #     
    # --------------------------------------------------------------
    # one "review wrapper" in each "review container"
    #
    # a "review wrapper" will contain the 1 or more reviews that 
    # exist in the "review container"
    # --------------------------------------------------------------
    review.wrapper <- html_nodes(review.containers[[i]], xpath = "div[@class='review-wrapper']")
    
    
    # --------------------------------------------------------------
    # take care of "review-content" div  
    #
    # there should be 1 and only 1 of these to grab at this point
    # --------------------------------------------------------------
    review.content.div <- html_node(review.wrapper, xpath = "div[@class='review-content']")
    
    
    # --------------------------------------------------------------
    #
    # things to extract from the "review-content" div
    #
    # - current review text
    # - current review rating
    # - useful vote count of current review
    # - funny vote count of current review
    # - cool vote count of current review
    #
    #
    # --------------------------------------------------------------
    
    review.text.node <- html_node(review.content.div, xpath = ".//p")
    # review.rating.node <- html_node(review.content.div, xpath = ".//i")
    review.rating.node <- html_node(review.content.div, xpath = ".//div[contains(@class, 'i-stars i-stars--regular')]")
    
    review.text <- html_text(review.text.node)
    review.text = gsub('"','',review.text)
    
    review.rating.temp <- html_attr(review.rating.node, name = "title")
    review.rating <- substr(review.rating.temp,1,3)
    
    review.date.node <- html_node(review.content.div,xpath = ".//span[@class='rating-qualifier']")
    review.date.temp <- html_text(review.date.node,trim = T)
    review.date.temp.pos.cleanup <- regexpr("\n", review.date.temp) 
    if(review.date.temp.pos.cleanup >= 1)
    {
      review.date.temp <- gsub("\n"," ",review.date.temp)
    }
    review.date <- substr(review.date.temp,1,10)
    
    
    
    # --------------------------------------------------------------
    # take care of "check-in i.e review_tags" div
    #
    # review tags may or may not exist for a particular
    # NA is assigned if a review_tags is not found
    # --------------------------------------------------------------
    
    #     review.tags.node.t1 <- tryCatch(html_node(review.content.div,xpath = "div[@class='review_tags']"),
    #                                     error = function(err){return(err)})
    
    review.tags.node.t1 <- tryCatch(html_node(review.content.div,xpath = "ul[@class='review-tags']"),
                                    error = function(err){return(err)})
    
    if(class(review.tags.node.t1)[1] == "xml_nodeset" )
      
    {  
      #       review.tags.node.t2 <- tryCatch(html_node(review.tags.node.t1,xpath = ".//span[@class='i-wrap ig-wrap-common_sprite i-18x18_checkin_c-common_sprite-wrap review-tag']"),
      #                                       error = function(err){return(err)})
      
      
      #       review.tags.node.t2 <- tryCatch(html_node(review.tags.node.t1,xpath = ".//span[contains(@class,'i-wrap ig-wrap-common_sprite i-18x18_checkin')]"),
      #                                       error = function(err){return(err)})
      #       
      
      review.tags.node.t2 <- tryCatch(html_node(review.tags.node.t1,xpath = ".//span[contains(@class,'i-wrap ig-wrap-common_sprite i-18x18')]"),
                                      error = function(err){return(err)})
      
      
      if(class(review.tags.node.t2)[1] == "xml_nodeset" )
        
      {
        review.tags.temp <- html_text(review.tags.node.t2)
        
        pos.check.in <- regexpr("check-in",review.tags.temp)
        
        if(pos.check.in > 0)
        {
          review.tags.checkin <- substr(review.tags.temp,1,(pos.check.in - 1))
        } else {
          review.tags.checkin <- "NA" 
        }
        #   
        
        #           print(review.tags.checkin)
      } else {
        
        review.tags.checkin <- "NA"
        #                  print(review.tags.checkin)
      }
      
    } else {
      
      review.tags.checkin <- "NA"
      
      #        print(review.tags.checkin)
      
    }
    
    # --------------------------------------------------------------
    # take care of "review-footer" div
    #
    # contains vote counts; useful, funny, and cool votes
    # --------------------------------------------------------------
    
    review.footer.div <- html_node(review.wrapper, xpath = "div[@class='review-footer clearfix']")
    
    useful.vote.node <- tryCatch(html_node(review.footer.div, xpath = ".//ul[@class='voting-buttons']//span[contains(@class, 'i-ufc-useful-common-wrap')]//span[@class='count']"),
                                 error = function(err){return(err)})
    if(class(useful.vote.node)[1] == "xml_nodeset" )
    {         
      
      funny.vote.node <- html_node(review.footer.div, xpath = ".//ul[@class='voting-buttons']//span[contains(@class, 'i-ufc-funny-common-wrap')]//span[@class='count']")
      cool.vote.node <- html_node(review.footer.div, xpath = ".//ul[@class='voting-buttons']//span[contains(@class, 'i-ufc-cool-common-wrap')]//span[@class='count']")
      
      useful.vote.count <- html_text(useful.vote.node)
      if (useful.vote.count == "") 
        useful.vote.count = "0"
      
      funny.vote.count <- html_text(funny.vote.node)
      if (funny.vote.count == "") 
        funny.vote.count = "0"
      
      cool.vote.count <- html_text(cool.vote.node)
      if (cool.vote.count == "") 
        cool.vote.count = "0"
    } else {
      
      useful.vote.count = "NA" 
      funny.vote.count = "NA"
      cool.vote.count = "NA"
      
      
    }
    
    list.index <- list.index + 1
    review.unique.id <- paste(list.index,"-",review.containers.unique.id)
    spam.biz.owner.temp.review.unique.id <- review.unique.id
    
    count.time <- 1
    time.review.unique.id[count.time] <- review.unique.id
    time.review.date[count.time] <- as.Date(review.date,"%m/%d/%Y")
    
    reviews[[list.index]] <- list(review.unique.id = review.unique.id,
                                  rest.id = rest.id,
                                  review.user.name = review.user.name,
                                  review.user.id = "NA",
                                  review.user.location = review.user.location,
                                  review.user.friends = review.user.friends,
                                  review.user.reviews = review.user.reviews,
                                  review.user.elite = review.user.elite,
                                  review.rating = review.rating,
                                  review.date = review.date,
                                  review.tags.checkin = review.tags.checkin,
                                  review.tags.first.to.review = "NA",
                                  review.tag.favorites.lists = "NA",
                                  review.tags.rotd = "NA",
                                  review.text = gsub("[\f\n\r\t\v]"," ",review.text), 
                                  review.photos.number = "NA",
                                  review.photos.text = "NA",
                                  useful.vote.count = useful.vote.count, 
                                  funny.vote.count = funny.vote.count, 
                                  cool.vote.count = cool.vote.count,
                                  review.comment = "Spam Current Review",
                                  identifier.business.owner = "NA")
    
    #     write.var <- as.data.frame(reviews[[list.index]])
    #     write.table(write.var,file = "SinglePageReviews.csv",append = T,col.names = F,row.names = F,sep = ",")
    #     #         
    call.write.to.file <- write.to.file(reviews[[list.index]])
    
    
    # --------------------------------------------------------------
    # take care of "previous-review" div
    # 
    # this div may or may not exist
    # most likely it will not exist
    #
    # --------------------------------------------------------------
    
    # previous.review.div <- html_node(review.wrapper, xpath = "div[@class='previous-review clearfix']")
    
    
    
    #     previous.review.div <- tryCatch(html_node(review.wrapper, xpath = "div[@class='previous-review clearfix']"),
    #                                     error = function(err){return(err)})
    #     
    #     
    #     
    #     if (class(previous.review.div)[1] == "xml_nodeset") {
    #       
    
    flag.previous.review = FALSE
    
    previous.review.div <- html_nodes(review.wrapper, xpath = "div[@class='previous-review clearfix']")
    
    if ((length(previous.review.div)) > 0) {
      
      flag.previous.review = TRUE
      
      #-------------------------------------------------------------------------
      # this for loop extracts all the previous reviews of a single user
      # ------------------------------------------------------------------------
      
      for(m in 1:length(previous.review.div))
        
      {  
        
        review.text.node <- tryCatch(html_node(previous.review.div[m], xpath = ".//span[@class='js-content-toggleable hidden']"),
                                     error = function(err){return(err)})
        
        #---------------------------------------------------------------------------------
        # the reviews will be two different xpaths based on number of lines of the review
        # 1) first xpath - if the review has more than one single
        # 2) second xpath - if the review is just one line
        #--------------------------------------------------------------------------------- 
        
        
        if (class(review.text.node)[1] == "xml_nodeset") {
          
          
          #---------------------------------------------------------------------
          # this if condition contains the code to retrieve the review that has
          # more mulitple lines
          #---------------------------------------------------------------------  
          
          
          review.text <- html_text(review.text.node)
          
          # review.rating.node <- html_node(previous.review.div[m], xpath = ".//i[contains(@class, 'star-img')]")
          review.rating.node <- html_node(previous.review.div[m], xpath = ".//div[contains(@class, 'i-stars i-stars--regular')]")
          
          review.rating <- substr(html_attr(review.rating.node, name = "title"), 1, 3)
          
          
          previous.review.date.node <- html_node(previous.review.div[m],xpath = ".//span[@class='rating-qualifier']")
          previous.review.date.temp <- html_text(previous.review.date.node,trim = T)
          
          previous.review.date.temp.pos.cleanup <- regexpr("\n", previous.review.date.temp) 
          if(previous.review.date.temp.pos.cleanup >= 1)
          {
            previous.review.date.temp <- gsub("\n"," ",previous.review.date.temp)
          }
          
          previous.review.date <- substr(previous.review.date.temp,1,10)
          
          useful.vote.node <- tryCatch(html_node(previous.review.div[m], xpath = ".//ul[@class='voting-buttons']//span[contains(@class, 'i-ufc-useful-common-wrap')]//span[@class='count']"),
                                       error = function(err){return(err)})
          if(class(useful.vote.node)[1] == "xml_nodeset" )
          {         
            
            funny.vote.node <- html_node(previous.review.div[m], xpath = ".//ul[@class='voting-buttons']//span[contains(@class, 'i-ufc-funny-common-wrap')]//span[@class='count']")
            cool.vote.node <- html_node(previous.review.div[m], xpath = ".//ul[@class='voting-buttons']//span[contains(@class, 'i-ufc-cool-common-wrap')]//span[@class='count']")
            
            useful.vote.count <- html_text(useful.vote.node)
            if (useful.vote.count == "") 
              useful.vote.count = "0"
            
            funny.vote.count <- html_text(funny.vote.node)
            if (funny.vote.count == "") 
              funny.vote.count = "0"
            
            cool.vote.count <- html_text(cool.vote.node)
            if (cool.vote.count == "") 
              cool.vote.count = "0"
          } else {
            
            useful.vote.count = "NA" 
            funny.vote.count = "NA"
            cool.vote.count = "NA"
            
            
          }
          
          
          list.index <- list.index + 1
          #       reviews[[list.index]] <- list(review.text = review.text, 
          #                                     review.rating = review.rating)
          #     
          review.unique.id <- paste(list.index,"-",review.containers.unique.id)
          
          count.time <- count.time + 1
          time.review.unique.id[count.time] <- review.unique.id
          time.review.date[count.time] <- as.Date(previous.review.date,"%m/%d/%Y")
          
          
          reviews[[list.index]] <- list(review.unique.id = review.unique.id,
                                        rest.id = rest.id,
                                        review.user.name = review.user.name,
                                        review.user.id ="NA",
                                        review.user.location = review.user.location,
                                        review.user.friends = review.user.friends,
                                        review.user.reviews = review.user.reviews,
                                        review.user.elite = review.user.elite,
                                        review.rating = review.rating,
                                        review.date = previous.review.date,
                                        review.tags.checkin = "NA",
                                        review.tags.first.to.review = "NA",
                                        review.tag.favorites.lists = "NA",
                                        review.tags.rotd = "NA",
                                        review.text = gsub("[\f\n\r\t\v]"," ",review.text),
                                        review.photos.number = "NA",
                                        review.photos.text = "NA",
                                        useful.vote.count = useful.vote.count, 
                                        funny.vote.count = funny.vote.count, 
                                        cool.vote.count = cool.vote.count,
                                        review.comment = "Spam Previous Review",
                                        identifier.business.owner = "NA")
          
          
          
          #         write.var <- as.data.frame(reviews[[list.index]])
          #         write.table(write.var,file = "SinglePageReviews.csv",append = T,col.names = F,row.names = F,sep = ",")
          #         #  
          call.write.to.file <- write.to.file(reviews[[list.index]])
          
          
        } else {
          
          #-----------------------------------------------------------------------
          # else condition is to retrieve the review that has a single line
          #-----------------------------------------------------------------------
          
          review.text.temp <- trimws(gsub("\n","",html_text(previous.review.div[m], trim = T)))
          pos.start.ext <- (regexpr("Previous review",review.text.temp) + nchar("Previous review"))
          # pos.end.ext <- (regexpr("Was this review",review.text.temp) - 1)
          pos.end.ext <- nchar(review.text.temp)
          review.text <- trimws(substr(review.text.temp,pos.start.ext,pos.end.ext))
          
          
          
          # changing this without actually encountering the error - 30 Dec 2016
          review.rating.node <- html_node(previous.review.div[m], xpath = ".//div[contains(@class, 'i-stars i-stars--regular')]")
          
          review.rating <- substr(html_attr(review.rating.node, name = "title"), 1, 3)
          
          
          previous.review.date.node <- html_node(previous.review.div[m],xpath = ".//span[@class='rating-qualifier']")
          previous.review.date.temp <- html_text(previous.review.date.node,trim = T)
          previous.review.date.temp.pos.cleanup <- regexpr("\n", previous.review.date.node) 
          if(previous.review.date.temp.pos.cleanup >= 1)
          {
            previous.review.date.temp <- gsub("\n"," ",previous.review.date.temp)
          }
          
          previous.review.date <- substr(previous.review.date.temp,1,10)
          
          
          useful.vote.node <- tryCatch(html_node(previous.review.div[m], xpath = ".//ul[@class='voting-buttons']//span[contains(@class, 'i-ufc-useful-common-wrap')]//span[@class='count']"),
                                       error = function(err){return(err)})
          if(class(useful.vote.node)[1] == "xml_nodeset" )
          {         
            
            funny.vote.node <- html_node(previous.review.div[m], xpath = ".//ul[@class='voting-buttons']//span[contains(@class, 'i-ufc-funny-common-wrap')]//span[@class='count']")
            cool.vote.node <- html_node(previous.review.div[m], xpath = ".//ul[@class='voting-buttons']//span[contains(@class, 'i-ufc-cool-common-wrap')]//span[@class='count']")
            
            useful.vote.count <- html_text(useful.vote.node)
            if (useful.vote.count == "") 
              useful.vote.count = "0"
            
            funny.vote.count <- html_text(funny.vote.node)
            if (funny.vote.count == "") 
              funny.vote.count = "0"
            
            cool.vote.count <- html_text(cool.vote.node)
            if (cool.vote.count == "") 
              cool.vote.count = "0"
          } else {
            
            useful.vote.count = "NA" 
            funny.vote.count = "NA"
            cool.vote.count = "NA"
            
            
          }
          
          
          list.index <- list.index + 1
          #       reviews[[list.index]] <- list(review.text = review.text, 
          #                                     review.rating = review.rating)
          #     
          review.unique.id <- paste(list.index,"-",review.containers.unique.id)
          
          count.time <- count.time + 1
          time.review.unique.id[count.time] <- review.unique.id
          time.review.date[count.time] <- as.Date(previous.review.date,"%m/%d/%Y")
          
          reviews[[list.index]] <- list(review.unique.id = review.unique.id,
                                        rest.id = rest.id,
                                        review.user.name = review.user.name,
                                        review.user.id ="NA",
                                        review.user.location = review.user.location,
                                        review.user.friends = review.user.friends,
                                        review.user.reviews = review.user.reviews,
                                        review.user.elite = review.user.elite,
                                        review.rating = review.rating, 
                                        review.date = previous.review.date,
                                        review.tags.checkin = "NA",
                                        review.tags.first.to.review = "NA",
                                        review.tag.favorites.lists = "NA",
                                        review.tags.rotd = "NA",
                                        review.text = gsub("[\f\n\r\t\v]"," ",review.text),
                                        review.photos.number = "NA",
                                        review.photos.text = "NA",
                                        useful.vote.count = useful.vote.count, 
                                        funny.vote.count = funny.vote.count, 
                                        cool.vote.count = cool.vote.count,
                                        review.comment = "Spam Previous Review",
                                        identifier.business.owner = "NA")
          
          
          
          #       write.var <- as.data.frame(reviews[[list.index]])
          #       write.table(write.var,file = "SinglePageReviews.csv",append = T,col.names = F,row.names = F,sep = ",")
          #       #      
          #       
          call.write.to.file <- write.to.file(reviews[[list.index]])
          
        }  
        
      }     # end of m loop 
      
    }   
    
    previous.review.div <- ""  
    # --------------------------------------------------------------
    # take care of "Comment from Business owner" div
    # 
    # this div may or may not exist
    # most likely it will not exist
    #
    # --------------------------------------------------------------
    
    # previous.review.div <- html_node(review.wrapper, xpath = "div[@class='previous-review clearfix']")
    
    
    
    business.owner.comment <- tryCatch(html_node(review.wrapper, xpath = "div[@class='island biz-owner-reply clearfix']"),
                                       error = function(err){return(err)})
    
    
    
    # if (!is.null(previous.review.div[[1]])) {
    if (class(business.owner.comment)[1] == "xml_nodeset") {
      
      
      review.text.node <- tryCatch(html_node(business.owner.comment, xpath = ".//span[@class='js-content-toggleable hidden']"),
                                   error = function(err){return(err)})
      
      if (class(review.text.node)[1] == "xml_nodeset") {
        
        review.text <- html_text(review.text.node)
        
        
        business.owner.comment.date.node <- html_node(business.owner.comment, xpath = ".//span[@class='bullet-after']")
        
        business.owner.comment.date <- html_text(business.owner.comment.date.node,trim = T)
        
        
        list.index <- list.index + 1
        #       reviews[[list.index]] <- list(review.text = review.text)
        
        review.unique.id <- paste(list.index,"-",review.containers.unique.id)
        
        business.owner.comment.date <- as.Date(business.owner.comment.date,"%m/%d/%Y")
        
        
        if(flag.previous.review == TRUE)
        {
          
          time.diff.df <- data.frame(time.review.unique.id,time.review.date)
          time.diff.df$time.review.difference <- 0
          
          for(b in 1:nrow(time.diff.df))
          {
            time.diff.df$time.review.difference[b] <- as.numeric(difftime(business.owner.comment.date,time.review.date[b]))
          }
          
          #         time.diff.df <- time.diff.df[time.diff.df$time.review.difference >= 0,]
          #         biz.owner.temp.review.unique.id <- time.diff.df$time.review.unique.id[min(time.diff.df$time.review.difference)]
          time.diff.df <- time.diff.df[time.diff.df$time.review.difference >= 0,]
          
          min.select <- min(time.diff.df$time.review.difference)
          
          time.diff.df1 <- time.diff.df$time.review.unique.id[time.diff.df$time.review.difference == min.select]
          
          spam.biz.owner.temp.review.unique.id <- as.character(time.diff.df1)
          
        }
        
        
        
        reviews[[list.index]] <- list(review.unique.id = review.unique.id,
                                      rest.id = rest.id,
                                      review.user.name = review.user.name,
                                      review.user.id ="NA",
                                      review.user.location = review.user.location,
                                      review.user.friends = review.user.friends,
                                      review.user.reviews = review.user.reviews,
                                      review.user.elite = review.user.elite,
                                      review.rating = "NA", 
                                      review.date = business.owner.comment.date,
                                      review.tags.checkin = "NA",
                                      review.tags.first.to.review = "NA",
                                      review.tag.favorites.lists = "NA",
                                      review.tags.rotd = "NA",
                                      review.text = gsub("[\f\n\r\t\v]"," ",review.text),
                                      review.photos.number = "NA",
                                      review.photos.text = "NA",
                                      useful.vote.count = "NA", 
                                      funny.vote.count = "NA", 
                                      cool.vote.count = "NA",
                                      review.comment = "Spam Business Owner Comment",
                                      identifier.business.owner = spam.biz.owner.temp.review.unique.id)
        
        
        
        #         write.var <- as.data.frame(reviews[[list.index]])
        #         write.table(write.var,file = "SinglePageReviews.csv",append = T,col.names = F,row.names = F,sep = ",")
        #         
        #         
        call.write.to.file <- write.to.file(reviews[[list.index]])
        
        
        #   #           
      } else {
        
        review.text.temp <- trimws(gsub("\n","",html_text(business.owner.comment, trim = T)))
        pos.start.ext <- (regexpr("/",review.text.temp) + 8)
        pos.end.ext <- nchar(review.text.temp)
        review.text <- trimws(substr(review.text.temp,pos.start.ext,pos.end.ext))
        
        business.owner.comment.date.node <- html_node(business.owner.comment, xpath = ".//span[@class='bullet-after']")
        
        business.owner.comment.date <- html_text(business.owner.comment.date.node,trim = T)
        
        
        list.index <- list.index + 1
        #       reviews[[list.index]] <- list(review.text = review.text)
        
        review.unique.id <- paste(list.index,"-",review.containers.unique.id)
        
        business.owner.comment.date <- as.Date(business.owner.comment.date,"%m/%d/%Y")
        
        
        if(flag.previous.review == TRUE)
        {
          
          time.diff.df <- data.frame(time.review.unique.id,time.review.date)
          time.diff.df$time.review.difference <- 0
          
          for(b in 1:nrow(time.diff.df))
          {
            time.diff.df$time.review.difference[b] <- as.numeric(difftime(business.owner.comment.date,time.review.date[b]))
          }
          
          #         time.diff.df <- time.diff.df[time.diff.df$time.review.difference >= 0,]
          #         biz.owner.temp.review.unique.id <- time.diff.df$time.review.unique.id[min(time.diff.df$time.review.difference)]
          time.diff.df <- time.diff.df[time.diff.df$time.review.difference >= 0,]
          
          min.select <- min(time.diff.df$time.review.difference)
          
          time.diff.df1 <- time.diff.df$time.review.unique.id[time.diff.df$time.review.difference == min.select]
          
          spam.biz.owner.temp.review.unique.id <- as.character(time.diff.df1)
          
        }
        
        
        reviews[[list.index]] <- list(review.unique.id = review.unique.id,
                                      rest.id = rest.id,
                                      review.user.name = review.user.name,
                                      review.user.id ="NA",
                                      review.user.location = review.user.location,
                                      review.user.friends = review.user.friends,
                                      review.user.reviews = review.user.reviews,
                                      review.user.elite = review.user.elite,
                                      review.rating = "NA", 
                                      review.date = business.owner.comment.date,
                                      review.tags.checkin = "NA",
                                      review.tags.first.to.review = "NA",
                                      review.tag.favorites.lists = "NA",
                                      review.tags.rotd = "NA",
                                      review.text = gsub("[\f\n\r\t\v]"," ",review.text),
                                      review.photos.number = "NA",
                                      review.photos.text = "NA",
                                      useful.vote.count = "NA", 
                                      funny.vote.count = "NA", 
                                      cool.vote.count = "NA",
                                      review.comment = "Spam Business Owner Comment",
                                      identifier.business.owner = spam.biz.owner.temp.review.unique.id)
        
        
        
        #         write.var <- as.data.frame(reviews[[list.index]])
        #         write.table(write.var,file = "SinglePageReviews.csv",append = T,col.names = F,row.names = F,sep = ",")
        
        call.write.to.file <- write.to.file(reviews[[list.index]])
        
        
      }
      
      
    }    
    
    # TODO:  extract more stuff here
    
    
  }
  
  return(list.index)
  
}   # end of function processSpamReviewContainers



#-----------------------END--------------------------------------------
# -----FETECH SPAM REVIEWS AND OTHER FIELDS FROM YELP WEBSITE---------------
#----------------------------------------------------------------------





#---------------START--------------------------------------------------
# -----FETECH REVIEWS AND OTHER FIELDS FROM YELP WEBSITE---------------
#----------------------------------------------------------------------


processReviewContainers <- function(review.containers,rest.id,list.index) {
  
  # print(rest.id)
  
  #   list.index <- 0
  
  reviews <- list()
  
  
  for (i in 1:length(review.containers)) {
    
    # Reset all loop variables here 
    
    previous.review.div <- ""
    
    
    #---------------------------------------------------------------------------------------
    # Setting review.tags.first.to.review to NA as not every wrapper will have a review.tag
    #---------------------------------------------------------------------------------------
    #     review.tags.first.to.review <- "NA"
    
    
    time.review.unique.id <- ""
    time.review.date <- ""
    time.review.date <- as.Date(c("0/00/0000"),"%m/%d/%Y")
    
    #    print(rest.id) 
    # --------------------------------------------------------------
    # TODO:
    # each "review container" will have one "review sidebar" div
    # take care of the "review sidebar" div here
    # the review.user.id lines are added to get the unique user - id 
    # --------------------------------------------------------------
    review.containers.unique.id <- html_attr(review.containers[i],name = "data-review-id")
    review.sidebar <- html_nodes(review.containers[[i]], xpath = "div[@class='review-sidebar']")
    review.sidebar.content <- html_nodes(review.sidebar, xpath = "div[@class='review-sidebar-content']")
    review.ypassport.media.block <- html_nodes(review.sidebar.content, xpath = "div[@class='ypassport media-block']")
    review.media.story <- html_node(review.ypassport.media.block, xpath = "div[@class='media-story']")
    
    review.user.name.node <- tryCatch(html_node(review.media.story,xpath = ".//li/a[@class='user-display-name']"),
                                      error = function(err){return(err)})
    if(class(review.user.name.node)[1] == "xml_nodeset" )
    {
      review.user.name <- html_text(review.user.name.node)
      review.user.id.t1 <- html_attr(review.user.name.node,name = "href")
      review.user.id.pos.start <- regexpr("=",review.user.id.t1) + 1
      review.user.id.pos.stop <- nchar(review.user.id.t1)
      review.user.id <- substr(review.user.id.t1,review.user.id.pos.start,review.user.id.pos.stop)
      #       print(paste0("In the source ",i,review.user.id))
      
    } else {
      
      review.user.name.node.t1 <- html_node(review.media.story,xpath = ".//li[@class='user-name']")
      
      review.user.name <- html_text(review.user.name.node.t1,trim = T)
      
      review.user.id.node <- html_node(review.user.name.node.t1,xpath = "a")
      
      review.user.id.t1 <- html_attr(review.user.id.node,name = "href")
      review.user.id.pos.start <- regexpr("=",review.user.id.t1) + 1
      review.user.id.pos.stop <- nchar(review.user.id.t1)
      review.user.id <- substr(review.user.id.t1,review.user.id.pos.start,review.user.id.pos.stop)
      
      
    }
    
    # review.user.location.node <- html_node(review.media.story,xpath = ".//li[@class='user-location']")
    review.user.location.node <- html_node(review.media.story,xpath = ".//li[@class='user-location responsive-hidden-small']")
    review.user.location <- html_text(review.user.location.node, trim = T)
    review.user.friends.node.t1 <- html_node(review.media.story,xpath = ".//li[@class='friend-count responsive-small-display-inline-block']")
    # review.user.friends.node.t2 <- html_node(review.user.friends.node.t1,xpath = ".//span[@class='i-wrap ig-wrap-common_sprite i-18x18_friends_c-common_sprite-wrap']")
    review.user.friends.node.t3 <- html_node(review.user.friends.node.t1,xpath = ".//b")
    review.user.friends <- html_text(review.user.friends.node.t3)
    review.user.reviews.node.t1 <- html_node(review.media.story,xpath = ".//li[@class='review-count responsive-small-display-inline-block']")
    # review.user.reviews.node.t2 <- html_node(review.user.reviews.node.t1,xpath = ".//span[@class='i-wrap ig-wrap-common_sprite i-18x18_review_c-common_sprite-wrap']")
    review.user.reviews.node.t3 <- html_node(review.user.reviews.node.t1,xpath = ".//b")
    review.user.reviews <- html_text(review.user.reviews.node.t3)
    review.user.elite.node <- tryCatch(html_node(review.media.story,xpath =".//li[@class='is-elite responsive-small-display-inline-block']"),
                                       error = function(err){return(err)})
    if(class(review.user.elite.node)[1] == "xml_nodeset" )
    {         
      review.user.elite.t1 <- html_text(review.user.elite.node)
      review.user.elite <- trimws(gsub("\n","",review.user.elite.t1))
    } else {
      
      review.user.elite <- "NA"
    }       
    
    #     
    #             review.user.name
    #             
    #             review.user.location
    #             
    #             review.user.friends
    #             
    #             review.user.reviews
    
    
    
    # --------------------------------------------------------------
    # one "review wrapper" in each "review container"
    #
    # a "review wrapper" will contain the 1 or more reviews that 
    # exist in the "review container"
    # --------------------------------------------------------------
    review.wrapper <- html_nodes(review.containers[[i]], xpath = "div[@class='review-wrapper']")
    
    
    # --------------------------------------------------------------
    # take care of "review-content" div  
    #
    # there should be 1 and only 1 of these to grab at this point
    # --------------------------------------------------------------
    review.content.div <- html_node(review.wrapper, xpath = "div[@class='review-content']")
    
    
    # --------------------------------------------------------------
    #
    # things to extract from the "review-content" div
    #
    # - current review text
    # - current review rating
    # - useful vote count of current review
    # - funny vote count of current review
    # - cool vote count of current review
    #
    # - other things?
    #
    # --------------------------------------------------------------
    
    # review.text.node <- html_node(review.content.div, xpath = ".//p[@itemprop='description']")
    review.text.node <- html_node(review.content.div, xpath = "p")
    
    # review.rating.node <- html_node(review.content.div, xpath = ".//meta[@itemprop='ratingValue']")
    
    review.rating.node <- html_node(review.content.div, xpath = ".//div[contains(@class, 'i-stars i-stars--regular')]")
    
    review.text <- html_text(review.text.node)
    review.rating <- html_attr(review.rating.node, name = "title")
    review.rating <- substr(review.rating,1,1)
    
    review.date.node <- html_node(review.content.div,xpath = ".//span[@class='rating-qualifier']")
    review.date.temp <- html_text(review.date.node,trim = T)
    review.date.temp.pos.cleanup <- regexpr("\n", review.date.temp) 
    if(review.date.temp.pos.cleanup >= 1)
    {
      review.date.temp <- gsub("\n"," ",review.date.temp)
    }
    review.date <- substr(review.date.temp,1,10)
    
    
    
    # --------------------------------------------------------------
    # take care of fields in review_tags" div
    # 
    # review tags may or may not exist for a particular
    # NA is assigned if a review_tags is not found
    # --------------------------------------------------------------
    review.wrapper.tags <- html_nodes(review.containers[[i]], xpath = "div[@class='review-wrapper']/div[@class='review-content']")
    
    review.tags.node.t1 <- tryCatch(html_nodes(review.wrapper.tags,xpath = "./ul[@class='review-tags']"),
                                    error = function(err){return(err)})
    
    # if(class(review.tags.node.t1)[1] == "xml_nodeset" )
    
    if(length(review.tags.node.t1) > 0)
      
    {
      set.rotd <- F
      set.checkin <- F
      set.listed <- F
      set.ftr <- F
      
      for(kk in 1:length(review.tags.node.t1))
        
      {
        
        review.tags.item.node <- tryCatch(html_nodes(review.tags.node.t1[kk],xpath = "./li[@class='review-tags_item']"),
                                          error = function(err){return(err)})
        
        for(kkk in 1:length(review.tags.item.node))
          
        {
          extract.item.node.t1 <- html_text(review.tags.item.node[kkk])
          extract.item.node.t2 <- gsub("\n","",extract.item.node.t1)
          extract.item.node.t3 <- trimws(extract.item.node.t2)
          #       print(extract.item.node.t3)
          
          #--------------------------------------------------------------------------
          #    TO FETCH FIRST TO REVIEW TAG
          #--------------------------------------------------------------------------  
          
          if(regexpr("First to Review",extract.item.node.t3) >= 1)
          {
            review.tags.first.to.review <- "First to Review"
            set.ftr <- T
          } 
          
          #           else {
          #             review.tags.first.to.review <- "NA"
          #           }
          
          #--------------------------------------------------------------------------
          #    TO FETCH CHECKIN TAG
          #--------------------------------------------------------------------------  
          
          pos.check.in <- regexpr("check-in",extract.item.node.t3)
          
          if(pos.check.in >= 1)
          {
            
            review.tags.checkin <- substr(extract.item.node.t3,1,(pos.check.in - 1))
            set.checkin <- T
          } 
          #           else {
          #             review.tags.checkin <- "NA"
          #           }
          
          #--------------------------------------------------------------------------
          #    TO FETCH LISTED IN TAG
          #--------------------------------------------------------------------------  
          
          
          if(regexpr("Listed",extract.item.node.t3) >= 1)
          {
            review.tag.favorites.lists <- extract.item.node.t3
            set.listed <- T
          } 
          #           else {
          #             review.tag.favorites.lists <- "NA"
          #           }
          
          
          #--------------------------------------------------------------------------
          #    TO FETCH ROTD (Review of the day)
          #--------------------------------------------------------------------------  
          
          if(regexpr("ROTD",extract.item.node.t3) == 1)
          {
            review.tags.rotd <- substr(extract.item.node.t3,6,(nchar(extract.item.node.t3)))
            set.rotd <- T
          } 
          #           else {
          #             review.tags.rotd <- "NA"
          #           }
          
          
          
        }  # end of review tag items
        
      } # end of review tags
      
      if(set.ftr)
      {
        review.tags.first.to.review <- review.tags.first.to.review
      } else {
        review.tags.first.to.review <- "NA"
      }
      
      if(set.checkin)
      {
        review.tags.checkin <- review.tags.checkin
      } else {
        review.tags.checkin <- "NA"
      }
      
      if(set.listed)
      {
        review.tag.favorites.lists <- review.tag.favorites.lists
      } else {
        review.tag.favorites.lists <- "NA"
      }
      
      if(set.rotd)
      {
        review.tags.rotd <- review.tags.rotd
      } else {
        review.tags.rotd <- "NA"
      }
      
    } else {
      
      #---------------------------------------------------------
      # COMES HERE IF NO REVIEW TAG IS FOUND IN THE WRAPPER TAG
      #---------------------------------------------------------
      
      review.tags.checkin <- "NA"
      review.tags.first.to.review <- "NA"
      review.tag.favorites.lists <- "NA"
      review.tags.rotd <- "NA"
      #        print(review.tags.checkin)
      
    }
    
    
    # ------------------------------------------------------------------
    # To Extract Number of pictures in a Review and corresponding texts
    # ------------------------------------------------------------------
    
    review.photos.node <- html_nodes(review.content.div, xpath = ".//ul[@class='photo-box-grid clearfix js-content-expandable lightbox-media-parent']")
    
    if(length(review.photos.node) == 1)
      
    {
      review.photos.text.node <- html_nodes(review.photos.node, xpath = ".//div[@class='photo-box-overlay js-overlay']")
      
      #       review.photos.number <- length(review.photos.text.node)
      
      review.photos.number <- length(html_children(review.photos.node))
      
      review.photos.text.temp <- html_text(review.photos.text.node,trim = T)
      
      review.photos.text <- paste0(review.photos.text.temp,collapse = "|")
      
      if(review.photos.text == "")
      {
        review.photos.text <- "NA"
      }
      
      
    } else {
      
      review.photos.number <- "NA"
      review.photos.text <- "NA"
      
      
    }
    
    # --------------------------------------------------------------
    # take care of "review-footer" div
    #
    # contains vote counts; useful, funny, and cool votes
    # --------------------------------------------------------------
    
    review.footer.div <- html_node(review.wrapper, xpath = "div[@class='review-footer clearfix']")
    
    #     useful.vote.node <- tryCatch(html_node(review.footer.div, xpath = ".//ul[@class='voting-buttons']//span[contains(@class, 'i-ufc-useful-common-wrap')]//span[@class='count']"),
    #                                  error = function(err){return(err)})
    
    #     useful.vote.node <- tryCatch(html_node(review.footer.div, xpath = ".//ul[@class='voting-buttons']"),
    #                                  error = function(err){return(err)})
    
    useful.vote.node <- tryCatch(html_node(review.footer.div, xpath = ".//ul[@class='voting-buttons']//a[contains(@class, 'ybtn ybtn--small useful js-analytics-click')]//span[@class='count']"),
                                 error = function(err){return(err)})
    
    
    if(class(useful.vote.node)[1] == "xml_nodeset" )
    {         
      
      #       vote.node <- html_nodes(useful.vote.node, xpath = ".//li")
      
      #       button.node <- html_node(vote.node[1], xpath = ".//span[@class='vote-type']")
      
      funny.vote.node <- html_node(review.footer.div, xpath = ".//ul[@class='voting-buttons']//a[contains(@class, 'ybtn ybtn--small funny js-analytics-click')]//span[@class='count']")
      cool.vote.node <- html_node(review.footer.div, xpath = ".//ul[@class='voting-buttons']//a[contains(@class, 'ybtn ybtn--small cool js-analytics-click')]//span[@class='count']")
      
      useful.vote.count <- html_text(useful.vote.node)
      if (useful.vote.count == "") 
        useful.vote.count = "0"
      
      funny.vote.count <- html_text(funny.vote.node)
      if (funny.vote.count == "") 
        funny.vote.count = "0"
      
      cool.vote.count <- html_text(cool.vote.node)
      if (cool.vote.count == "") 
        cool.vote.count = "0"
    } else {
      
      useful.vote.count = "NA" 
      funny.vote.count = "NA"
      cool.vote.count = "NA"
      
      
    }
    
    list.index <- list.index + 1
    review.unique.id <- paste(list.index,"-",review.containers.unique.id)
    biz.owner.temp.review.unique.id <- review.unique.id
    
    
    count.time <- 1
    time.review.unique.id[count.time] <- review.unique.id
    time.review.date[count.time] <- as.Date(review.date,"%m/%d/%Y")
    #     print(paste0("Before Write ",i,review.user.id))
    
    reviews[[list.index]] <- list(review.unique.id = review.unique.id,
                                  rest.id = rest.id,
                                  review.user.name = review.user.name,
                                  review.user.id = review.user.id,
                                  review.user.location = review.user.location,
                                  review.user.friends = review.user.friends,
                                  review.user.reviews = review.user.reviews,
                                  review.user.elite = review.user.elite,
                                  review.rating = review.rating,
                                  review.date = review.date,
                                  review.tags.checkin = review.tags.checkin,
                                  review.tags.first.to.review = review.tags.first.to.review,
                                  review.tag.favorites.lists = review.tag.favorites.lists,
                                  review.tags.rotd = review.tags.rotd,
                                  review.text = gsub("[\f\n\r\t\v]"," ",review.text),
                                  review.photos.number = review.photos.number,
                                  review.photos.text = gsub("[\f\n\r\t\v]"," ",review.photos.text),
                                  #                                   review.photos.text = review.photos.text,
                                  useful.vote.count = useful.vote.count, 
                                  funny.vote.count = funny.vote.count, 
                                  cool.vote.count = cool.vote.count,
                                  review.comment = "Current Review",
                                  identifier.business.owner = "NA")
    
    
    
    
    #     write.var <- as.data.frame(reviews[[list.index]])
    #     write.table(write.var,file = "SinglePageReviews.csv",append = T,col.names = F,row.names = F,sep = ",")
    #     #         
    call.write.to.file <- write.to.file(reviews[[list.index]])
    
    # --------------------------------------------------------------
    # take care of "previous-review" div
    # 
    # this div may or may not exist
    # most likely it will not exist
    #
    # --------------------------------------------------------------
    
    # previous.review.div <- html_node(review.wrapper, xpath = "div[@class='previous-review clearfix']")
    
    
    
    #     previous.review.div <- tryCatch(html_nodes(review.wrapper, xpath = "div[@class='previous-review clearfix']"),
    #                                     error = function(err){return(err)})
    # 
    # if (class(previous.review.div)[1] == "xml_nodeset") {
    #     
    
    flag.previous.review = FALSE
    
    previous.review.div <- html_nodes(review.wrapper, xpath = "div[@class='previous-review clearfix']")
    
    if ((length(previous.review.div)) > 0) {
      
      flag.previous.review = TRUE
      
      for(m in 1:length(previous.review.div))
        
      {  
        
        review.text.node <- tryCatch(html_node(previous.review.div[m], xpath = ".//span[@class='js-content-toggleable hidden']"),
                                     error = function(err){return(err)})
        
        if (class(review.text.node)[1] == "xml_nodeset") {
          
          review.text <- html_text(review.text.node)
          
          # review.rating.node <- html_node(previous.review.div[m], xpath = ".//i[contains(@class, 'star-img')]")
          # changing this without actually encountering the error - 30 Dec 2016
          review.rating.node <- html_node(previous.review.div[m], xpath = ".//div[contains(@class, 'i-stars i-stars--regular')]")
          
          
          review.rating <- substr(html_attr(review.rating.node, name = "title"), 1, 3)
          
          
          previous.review.date.node <- html_node(previous.review.div[m],xpath = ".//span[@class='rating-qualifier']")
          previous.review.date.temp <- html_text(previous.review.date.node,trim = T)
          
          previous.review.date.temp.pos.cleanup <- regexpr("\n", previous.review.date.temp) 
          if(previous.review.date.temp.pos.cleanup >= 1)
          {
            previous.review.date.temp <- gsub("\n"," ",previous.review.date.temp)
          }
          
          previous.review.date <- substr(previous.review.date.temp,1,10)
          
          useful.vote.node <- tryCatch(html_node(previous.review.div[m], xpath = ".//ul[@class='voting-buttons']//a[contains(@class, 'ybtn ybtn--small useful js-analytics-click')]//span[@class='count']"),
                                       error = function(err){return(err)})
          if(class(useful.vote.node)[1] == "xml_nodeset" )
          {         
            
            funny.vote.node <- html_node(previous.review.div[m], xpath = ".//ul[@class='voting-buttons']//a[contains(@class, 'ybtn ybtn--small funny js-analytics-click')]//span[@class='count']")
            cool.vote.node <- html_node(previous.review.div[m], xpath = ".//ul[@class='voting-buttons']//a[contains(@class, 'ybtn ybtn--small cool js-analytics-click')]//span[@class='count']")
            
            useful.vote.count <- html_text(useful.vote.node)
            if (useful.vote.count == "") 
              useful.vote.count = "0"
            
            funny.vote.count <- html_text(funny.vote.node)
            if (funny.vote.count == "") 
              funny.vote.count = "0"
            
            cool.vote.count <- html_text(cool.vote.node)
            if (cool.vote.count == "") 
              cool.vote.count = "0"
          } else {
            
            useful.vote.count = "NA" 
            funny.vote.count = "NA"
            cool.vote.count = "NA"
            
            
          }
          
          
          list.index <- list.index + 1
          #       reviews[[list.index]] <- list(review.text = review.text, 
          #                                     review.rating = review.rating)
          #     
          review.unique.id <- paste(list.index,"-",review.containers.unique.id)
          
          
          count.time <- count.time + 1
          time.review.unique.id[count.time] <- review.unique.id
          time.review.date[count.time] <- as.Date(previous.review.date,"%m/%d/%Y")
          
          reviews[[list.index]] <- list(review.unique.id = review.unique.id,
                                        rest.id = rest.id,
                                        review.user.name = review.user.name,
                                        review.user.id = review.user.id,
                                        review.user.location = review.user.location,
                                        review.user.friends = review.user.friends,
                                        review.user.reviews = review.user.reviews,
                                        review.user.elite = review.user.elite,
                                        review.rating = review.rating,
                                        review.date = previous.review.date,
                                        review.tags.checkin = "NA",
                                        review.tags.first.to.review = "NA",
                                        review.tag.favorites.lists = "NA",
                                        review.tags.rotd = "NA",
                                        review.text = gsub("[\f\n\r\t\v]"," ",review.text),
                                        review.photos.number = "NA",
                                        review.photos.text = "NA",
                                        useful.vote.count = useful.vote.count, 
                                        funny.vote.count = funny.vote.count, 
                                        cool.vote.count = cool.vote.count,
                                        review.comment = "Previous Review",
                                        identifier.business.owner = "NA")
          
          
          
          
          #         write.var <- as.data.frame(reviews[[list.index]])
          #         write.table(write.var,file = "SinglePageReviews.csv",append = T,col.names = F,row.names = F,sep = ",")
          #         #  
          call.write.to.file <- write.to.file(reviews[[list.index]])
          
          
        } else {
          
          review.text.temp <- trimws(gsub("\n","",html_text(previous.review.div[m], trim = T)))
          pos.start.ext <- (regexpr("Previous review",review.text.temp) + nchar("Previous review"))
          pos.end.ext <- (regexpr("Was this review",review.text.temp) - 1)
          review.text <- trimws(substr(review.text.temp,pos.start.ext,pos.end.ext))
          
          # review.rating.node <- html_node(previous.review.div[m], xpath = ".//i[contains(@class, 'star-img')]")
          # changing this without actually encountering the error - 30 Dec 2016
          review.rating.node <- html_node(previous.review.div[m], xpath = ".//div[contains(@class, 'i-stars i-stars--regular')]")
          
          review.rating <- substr(html_attr(review.rating.node, name = "title"), 1, 3)
          
          
          previous.review.date.node <- html_node(previous.review.div[m],xpath = ".//span[@class='rating-qualifier']")
          previous.review.date.temp <- html_text(previous.review.date.node,trim = T)
          previous.review.date.temp.pos.cleanup <- regexpr("\n", previous.review.date.temp) 
          if(previous.review.date.temp.pos.cleanup >= 1)
          {
            previous.review.date.temp <- gsub("\n"," ",previous.review.date.temp)
          }
          
          previous.review.date <- substr(previous.review.date.temp,1,10)
          
          useful.vote.node <- tryCatch(html_node(previous.review.div[m], xpath = ".//ul[@class='voting-buttons']//span[contains(@class, 'i-ufc-useful-common-wrap')]//span[@class='count']"),
                                       error = function(err){return(err)})
          if(class(useful.vote.node)[1] == "xml_nodeset" )
          {         
            
            funny.vote.node <- html_node(previous.review.div[m], xpath = ".//ul[@class='voting-buttons']//span[contains(@class, 'i-ufc-funny-common-wrap')]//span[@class='count']")
            cool.vote.node <- html_node(previous.review.div[m], xpath = ".//ul[@class='voting-buttons']//span[contains(@class, 'i-ufc-cool-common-wrap')]//span[@class='count']")
            
            useful.vote.count <- html_text(useful.vote.node)
            if (useful.vote.count == "") 
              useful.vote.count = "0"
            
            funny.vote.count <- html_text(funny.vote.node)
            if (funny.vote.count == "") 
              funny.vote.count = "0"
            
            cool.vote.count <- html_text(cool.vote.node)
            if (cool.vote.count == "") 
              cool.vote.count = "0"
          } else {
            
            useful.vote.count = "NA" 
            funny.vote.count = "NA"
            cool.vote.count = "NA"
            
            
          }
          
          
          
          list.index <- list.index + 1
          #       reviews[[list.index]] <- list(review.text = review.text, 
          #                                     review.rating = review.rating)
          #     
          review.unique.id <- paste(list.index,"-",review.containers.unique.id)
          
          count.time <- count.time + 1
          time.review.unique.id[count.time] <- review.unique.id
          time.review.date[count.time] <- as.Date(previous.review.date,"%m/%d/%Y")
          
          
          reviews[[list.index]] <- list(review.unique.id = review.unique.id,
                                        rest.id = rest.id,
                                        review.user.name = review.user.name,
                                        review.user.id = review.user.id,
                                        review.user.location = review.user.location,
                                        review.user.friends = review.user.friends,
                                        review.user.reviews = review.user.reviews,
                                        review.user.elite = review.user.elite,
                                        review.rating = review.rating, 
                                        review.date = previous.review.date,
                                        review.tags.checkin = "NA",
                                        review.tags.first.to.review = "NA",
                                        review.tag.favorites.lists = "NA",
                                        review.tags.rotd = "NA",
                                        review.text = gsub("[\f\n\r\t\v]"," ",review.text),
                                        review.photos.number = "NA",
                                        review.photos.text = "NA",
                                        useful.vote.count = useful.vote.count, 
                                        funny.vote.count = funny.vote.count, 
                                        cool.vote.count = cool.vote.count,
                                        review.comment = "Previous Review",
                                        identifier.business.owner = "NA")
          
          
          
          
          #       write.var <- as.data.frame(reviews[[list.index]])
          #       write.table(write.var,file = "SinglePageReviews.csv",append = T,col.names = F,row.names = F,sep = ",")
          #       #      
          #       
          call.write.to.file <- write.to.file(reviews[[list.index]])
          
        }  
        
      }      # end of m loop   
      
    }
    
    previous.review.div <- ""  
    # --------------------------------------------------------------
    
    
    # --------------------------------------------------------------
    # take care of "Comment from Business owner" div
    # 
    # this div may or may not exist
    # most likely it will not exist
    #
    # --------------------------------------------------------------
    
    # previous.review.div <- html_node(review.wrapper, xpath = "div[@class='previous-review clearfix']")
    
    
    
    business.owner.comment <- tryCatch(html_node(review.wrapper, xpath = "div[@class='island biz-owner-reply clearfix']"),
                                       error = function(err){return(err)})
    
    
    
    # if (!is.null(previous.review.div[[1]])) {
    if (class(business.owner.comment)[1] == "xml_nodeset") {
      
      
      review.text.node <- tryCatch(html_node(business.owner.comment, xpath = ".//span[@class='js-content-toggleable hidden']"),
                                   error = function(err){return(err)})
      
      if (class(review.text.node)[1] == "xml_nodeset") {
        
        review.text <- html_text(review.text.node)
        
        
        business.owner.comment.date.node <- html_node(business.owner.comment, xpath = ".//span[@class='bullet-after']")
        
        business.owner.comment.date <- html_text(business.owner.comment.date.node,trim = T)
        
        
        list.index <- list.index + 1
        #       reviews[[list.index]] <- list(review.text = review.text)
        
        review.unique.id <- paste(list.index,"-",review.containers.unique.id)
        
        business.owner.comment.date <- as.Date(business.owner.comment.date,"%m/%d/%Y")
        
        
        if(flag.previous.review == TRUE)
        {
          
          time.diff.df <- data.frame(time.review.unique.id,time.review.date)
          time.diff.df$time.review.difference <- 0
          
          for(b in 1:nrow(time.diff.df))
          {
            time.diff.df$time.review.difference[b] <- as.numeric(difftime(business.owner.comment.date,time.review.date[b]))
          }
          
          #         time.diff.df <- time.diff.df[time.diff.df$time.review.difference >= 0,]
          #         biz.owner.temp.review.unique.id <- time.diff.df$time.review.unique.id[min(time.diff.df$time.review.difference)]
          time.diff.df <- time.diff.df[time.diff.df$time.review.difference >= 0,]
          
          min.select <- min(time.diff.df$time.review.difference)
          
          time.diff.df1 <- time.diff.df$time.review.unique.id[time.diff.df$time.review.difference == min.select]
          
          biz.owner.temp.review.unique.id <- as.character(time.diff.df1)
          
        }
        
        reviews[[list.index]] <- list(review.unique.id = review.unique.id,
                                      rest.id = rest.id,
                                      review.user.name = review.user.name,
                                      review.user.id = review.user.id,
                                      review.user.location = review.user.location,
                                      review.user.friends = review.user.friends,
                                      review.user.reviews = review.user.reviews,
                                      review.user.elite = review.user.elite,
                                      review.rating = "NA", 
                                      review.date = business.owner.comment.date,
                                      review.tags.checkin = "NA",
                                      review.tags.first.to.review = "NA",
                                      review.tag.favorites.lists = "NA",
                                      review.tags.rotd = "NA",
                                      review.text = gsub("[\f\n\r\t\v]"," ",review.text),
                                      review.photos.number = "NA",
                                      review.photos.text = "NA",
                                      useful.vote.count = "NA", 
                                      funny.vote.count = "NA", 
                                      cool.vote.count = "NA",
                                      review.comment = "Business Owner Comment",
                                      identifier.business.owner = biz.owner.temp.review.unique.id)
        
        
        
        #         write.var <- as.data.frame(reviews[[list.index]])
        #         write.table(write.var,file = "SinglePageReviews.csv",append = T,col.names = F,row.names = F,sep = ",")
        #         
        #         
        call.write.to.file <- write.to.file(reviews[[list.index]])
        
        
        #   #           
      } else {
        
        review.text.temp <- trimws(gsub("\n","",html_text(business.owner.comment, trim = T)))
        pos.start.ext <- (regexpr("/",review.text.temp) + 8)
        pos.end.ext <- nchar(review.text.temp)
        review.text <- trimws(substr(review.text.temp,pos.start.ext,pos.end.ext))
        
        business.owner.comment.date.node <- html_node(business.owner.comment, xpath = ".//span[@class='bullet-after']")
        
        business.owner.comment.date <- html_text(business.owner.comment.date.node,trim = T)
        
        
        list.index <- list.index + 1
        #       reviews[[list.index]] <- list(review.text = review.text)
        
        review.unique.id <- paste(list.index,"-",review.containers.unique.id)
        
        business.owner.comment.date <- as.Date(business.owner.comment.date,"%m/%d/%Y")
        
        
        if(flag.previous.review == TRUE)
        {
          
          time.diff.df <- data.frame(time.review.unique.id,time.review.date)
          time.diff.df$time.review.difference <- 0
          
          for(b in 1:nrow(time.diff.df))
          {
            time.diff.df$time.review.difference[b] <- as.numeric(difftime(business.owner.comment.date,time.review.date[b]))
          }
          
          #         time.diff.df <- time.diff.df[time.diff.df$time.review.difference >= 0,]
          #         biz.owner.temp.review.unique.id <- time.diff.df$time.review.unique.id[min(time.diff.df$time.review.difference)]
          time.diff.df <- time.diff.df[time.diff.df$time.review.difference >= 0,]
          
          min.select <- min(time.diff.df$time.review.difference)
          
          time.diff.df1 <- time.diff.df$time.review.unique.id[time.diff.df$time.review.difference == min.select]
          
          biz.owner.temp.review.unique.id <- as.character(time.diff.df1)
          
        }
        
        reviews[[list.index]] <- list(review.unique.id = review.unique.id,
                                      rest.id = rest.id,
                                      review.user.name = review.user.name,
                                      review.user.id = review.user.id,
                                      review.user.location = review.user.location,
                                      review.user.friends = review.user.friends,
                                      review.user.reviews = review.user.reviews,
                                      review.user.elite = review.user.elite,
                                      review.rating = "NA", 
                                      review.date = business.owner.comment.date,
                                      review.tags.checkin = "NA",
                                      review.tags.first.to.review = "NA",
                                      review.tag.favorites.lists = "NA",
                                      review.tags.rotd = "NA",
                                      review.text = gsub("[\f\n\r\t\v]"," ",review.text), 
                                      review.photos.number = "NA",
                                      review.photos.text = "NA",
                                      useful.vote.count = "NA", 
                                      funny.vote.count = "NA", 
                                      cool.vote.count = "NA",
                                      review.comment = "Business Owner Comment",
                                      identifier.business.owner = biz.owner.temp.review.unique.id)
        
        
        
        #         write.var <- as.data.frame(reviews[[list.index]])
        #         write.table(write.var,file = "SinglePageReviews.csv",append = T,col.names = F,row.names = F,sep = ",")
        
        call.write.to.file <- write.to.file(reviews[[list.index]])
        
        
      }
      
      
    }    
    
    # TODO:  extract more stuff here
    
    
  }
  
  
  
  remove(time.diff.df)
  remove(time.diff.df1)
  return(list.index)
  
}   # end of function processReviewContainers

# -------------------------------------------------------

#-------------------------END------------------------------------------
# -----FETECH REVIEWS AND OTHER FIELDS FROM YELP WEBSITE---------------
#----------------------------------------------------------------------


#-------------------------START----------------------------------------
# ------------------WRITE DATA TO THE FILE-----------------------------
#----------------------------------------------------------------------



write.to.file <- function(reviews)
{
  
  # print(reviews[[list.index]])
  write.record <- paste(reviews[["review.unique.id"]][1],
                        reviews[["rest.id"]][1],
                        reviews[["review.user.name"]][1],
                        reviews[["review.user.id"]][1],
                        reviews[["review.user.location"]][1],
                        reviews[["review.user.friends"]][1],
                        reviews[["review.user.reviews"]][1],
                        reviews[["review.user.elite"]][1],
                        reviews[["review.rating"]][1],
                        reviews[["review.date"]][1],
                        reviews[["review.tags.checkin"]][1],
                        reviews[["review.tags.first.to.review"]][1],
                        reviews[["review.tag.favorites.lists"]][1],
                        reviews[["review.tags.rotd"]][1],
                        reviews[["review.text"]][1],
                        reviews[["review.photos.number"]][1],
                        reviews[["review.photos.text"]][1],
                        reviews[["useful.vote.count"]][1],
                        reviews[["funny.vote.count"]][1],
                        reviews[["cool.vote.count"]][1],
                        reviews[["review.comment"]][1],
                        reviews[["identifier.business.owner"]][1],
                        sep="\t")
  # print(write.record)
  write(write.record, file = "TotalReviews", append = TRUE)
  
  
  #----------------------------------------------------------------------
  # SAVING DATA IN .RDATA FORMAT
  #----------------------------------------------------------------------
  
#   backup.write.temp <- ""
#   backup.write.temp <- write.record
#   backup.write <<- c(backup.write,backup.write.temp)
#   #   print(backup.write)
#   save(backup.write, file = "Totalreviews.RData")
  
}


#-------------------------END------------------------------------------
# ------------------WRITE DATA TO THE FILE-----------------------------
#----------------------------------------------------------------------


#-------------------------START----------------------------------------
# ------------------WRITE HEADER TO THE FILE-----------------------------
#----------------------------------------------------------------------



write.header.to.file <- function(reviews)
{
  
  # print(reviews[[list.index]])
  write.header.record <- paste("review.unique.id",
                               "restaurant.id",
                               "review.user.name",
                               "review.user.id",
                               "review.user.location",
                               "review.user.friends",
                               "review.user.reviews",
                               "review.user.elite",
                               "review.rating",
                               "review.date",
                               "review.tags.checkin",
                               "review.tags.first.to.review",
                               "review.tag.favorites.lists",
                               "review.tags.rotd",
                               "review.text",
                               "review.photos.number",
                               "review.photos.text",
                               "useful.vote.count",
                               "funny.vote.count",
                               "cool.vote.count",
                               "review.comment",
                               "identifier.business.owner",
                               sep="\t")
  # print(write.record)
  write(write.header.record, file = "TotalReviews", append = TRUE)
  
}


#-------------------------END------------------------------------------
# ------------------WRITE HEADER TO THE FILE---------------------------
#----------------------------------------------------------------------

# ---------------------------------------------------------------------
# --------- FUNCTIONS INCLUDED FOR DAVID'S - ADDITIONAL INFO CODE -----
# ---------------------------------------------------------------------


# --------------------------------------------------------------

scriptInit <- function() {
  
  
  # ------------------------------------------------------------
  # load needed libraries
  # ------------------------------------------------------------
  library("rvest")
  library("urltools")
  
  
  SetConfigurationVariables()
  
  
  unlink(BUSINESS_HOURS_FILE)
  unlink(MORE_BUSINESS_INFO_FILE)
  unlink(BUSINESS_PRICE_RANGES_FILE)
  
  # ---------------------------------------------
  
  new.record <- paste("id",
                      "day",
                      "time.open", 
                      "time.close", 
                      sep = "\t")
  
  write(new.record, file = BUSINESS_HOURS_FILE, append = TRUE)
  
  # ---------------------------------------------
  
  new.record <- paste("id",
                      "business.attribute.name",
                      "business.attribute.value", 
                      sep = "\t")
  
  write(new.record, file = MORE_BUSINESS_INFO_FILE, append = TRUE)
  
  # ---------------------------------------------
  
  new.record <- paste("id",
                      "price.range.symbol",
                      "price.range",
                      "price.range.min",
                      "price.range.max",
                      sep = "\t")
  
  write(new.record, file = BUSINESS_PRICE_RANGES_FILE, append = TRUE)
  
  # ---------------------------------------------
  
  business.hours.data <<- c()
  business.more.data <<- c()
  business.price.range.data <<- c()
  
}    # end of function scriptInit()


# ------------------------------------------------------------------

SetConfigurationVariables <- function() {
  
  # ------------------------------------------------------------
  # TODO:
  # change to read value from xml config file
  # ------------------------------------------------------------
  
  # USER_STATS_FILE <<- "user_stats.txt"
  
  # USER_IDS_INPUT_FILE <<- "UserAttributesYelpingSince"
  
  
  # ------------------------------------------------------------
  # input file
  # ------------------------------------------------------------
  
  # BUSINESS_DATA_FILE <<- "unique_businesses_test_001.txt"
  
  #   BUSINESS_DATA_FILE <<- "unique_bussinesses_seattle.txt"
  
  
  # ------------------------------------------------------------
  # output files
  # ------------------------------------------------------------
  
  #   BUSINESS_HOURS_FILE <<- "business_hours_test_001.txt"
  #   MORE_BUSINESS_INFO_FILE <<- "more_business_info_test_001.txt"
  
  # - - - - - - - -
  
  #   BUSINESS_HOURS_RDATA_FILE <<- "business_hours_test_001.RData"
  #   MORE_BUSINESS_INFO_RDATA_FILE <<- "more_business_info_test_001.RData"
  
  # - - - - - - - -
  
  BUSINESS_HOURS_FILE <<- "business_hours.txt"
  MORE_BUSINESS_INFO_FILE <<- "more_business_info.txt"
  
  BUSINESS_PRICE_RANGES_FILE <<- "business_price_ranges.txt"
  
  # - - - - - - - -
  
  BUSINESS_HOURS_RDATA_FILE <<- "business_hours.RData"
  MORE_BUSINESS_INFO_RDATA_FILE <<- "more_business_info.RData"
  
  BUSINESS_PRICE_RANGES_RDATA_FILE <<- "business_price_ranges.RData"
  
  # - - - - - - - -
  
  return(0)
}

# --------------------------------------------------------------


processDayAndHoursNode <- function(day.and.hours.node, business.id) {
  
  # ------------------------------------------------------------
  # extract 3 pieces of info from each node 
  # that is processed in this function
  #
  #   1) day of week
  #   2) open time
  #   3) close time
  # ------------------------------------------------------------
  
  week.day.node <- html_node(day.and.hours.node, xpath = "./th")
  week.day <- html_text(week.day.node)
  
  open.and.close.time.nodes <- html_nodes(day.and.hours.node, xpath = "./td/span")
  
  if (length(open.and.close.time.nodes) >= 2) {
    
    open.time <- html_text(open.and.close.time.nodes[[1]])
    close.time <- html_text(open.and.close.time.nodes[[2]])
    
    # --------------------------------------------------------
    # in a single day, some businesses will:
    #
    # open
    # close for a while
    # open again
    # then close for the day
    #
    # therefore, below we look for another pair of open and 
    # close times
    #
    # --------------------------------------------------------
    
    if (length(open.and.close.time.nodes) > 3) {
      
      new.record <- paste(business.id,
                          week.day,
                          open.time, 
                          close.time, 
                          sep = "\t")
      
      write(new.record, file = BUSINESS_HOURS_FILE, append = TRUE)
      
      
#       business.hours.data <<- c(business.hours.data, new.record)
#       save(business.hours.data, file = BUSINESS_HOURS_RDATA_FILE)
#       
      
      open.time <- html_text(open.and.close.time.nodes[[3]])
      close.time <- html_text(open.and.close.time.nodes[[4]])
      
      # --------------------------------------------------------
      # continue on as we used to when we assumed there was 
      # only a single pair of open/close times
      # --------------------------------------------------------
      
    }
    
  }
  else {
    
    open.time <- "Closed"
    close.time <- ""
  }
  
  
  # cat("week day: ", week.day, " - ", open.time, " - ", close.time, "\n")
  
  # ---------------------------------------------
  
  new.record <- paste(business.id,
                      week.day,
                      open.time, 
                      close.time, 
                      sep = "\t")
  
  write(new.record, file = BUSINESS_HOURS_FILE, append = TRUE)
  
  
#   business.hours.data <<- c(business.hours.data, new.record)
#   save(business.hours.data, file = BUSINESS_HOURS_RDATA_FILE)
  
  
  # ---------------------------------------------
  
  return(0)
  
}    # end of function processDayAndHoursNode()

# --------------------------------------------------------------



processMoreBusinessInfo <- function(htmlpage, business.id) {
  
  div.wrapper.node <- tryCatch(html_node(htmlpage, xpath = "//div[h3='More business info']"),
                               error = function(err) {
                                 return(err)
                               })
  
  if (class(div.wrapper.node)[1] == "xml_node") {
    
    # all is good - no "No matches" error thrown by html_node()
    
    business.attribute.nodes <- html_nodes(div.wrapper.node, xpath = ".//dl")
    
    if (length(business.attribute.nodes) > 0) {
      for (i in 1:length(business.attribute.nodes)) {
        
        attribute.name.node <- html_node(business.attribute.nodes[[i]], xpath = "./dt")
        attribute.value.node <- html_node(business.attribute.nodes[[i]], xpath = "./dd")
        
        attribute.name <- html_text(attribute.name.node)
        attribute.value <- html_text(attribute.value.node)
        
        attribute.name <- gsub("[\f\n\r\t\v]", " ", attribute.name)
        attribute.name <- trimws(attribute.name, which = "both")
        
        attribute.value <- gsub("[\f\n\r\t\v]", " ", attribute.value)
        attribute.value <- trimws(attribute.value, which = "both")
        
        # ---------------------------------------------
        # write record to text file
        # ---------------------------------------------
        
        new.record <- paste(business.id,
                            attribute.name,
                            attribute.value, 
                            sep = "\t")
        
        write(new.record, file = MORE_BUSINESS_INFO_FILE, append = TRUE)
        
        
#         business.more.data <<- c(business.more.data, new.record)
#         save(business.more.data, file = MORE_BUSINESS_INFO_RDATA_FILE)
        
        
      }
    }
  } 
  else {
    
    cat("No 'more business info' for: ", business.id, "\n")
    # return(0)
  }
  
  #   if (class(div.wrapper.node)[1] == "NULL") {
  #     
  #     cat("No 'more business info' for: ", business.id, "\n")
  #     return(0)
  #   }
  
  return(0)
  
}    # end of function processMoreBusinessInfo()



# --------------------------------------------------------------


CollectPriceRangeData <- function(htmlpage, business.id) {
  
  price.range.symbol <- ""
  price.range <- ""
  price.range.min.and.max <- c("", "")
  
  # ------------------------------------------------------------
  # get the price range symbol
  # ------------------------------------------------------------
  
  xpath.expression = "//div[contains(@class, 'sidebar')]//span[@class='business-attribute price-range']"
  
  price.range.symbol.node <- tryCatch(html_node(htmlpage, xpath = xpath.expression),
                                      error = function(err) {
                                        return(err)
                                      })
  
  if (class(price.range.symbol.node)[1] == "xml_node") {
    
    # price.range.symbol <- html_attr(price.range.symbol.node, name = "data-remainder")
    
    price.range.symbol <- html_text(price.range.symbol.node)
    
    price.range.symbol <- gsub("[\f\n\r\t\v]", " ", price.range.symbol)
    price.range.symbol <- trimws(price.range.symbol, which = "both")
    
  } 
  
  # ------------------------------------------------------------
  # get the price range text
  # ------------------------------------------------------------
  
  xpath.expression = "//div[contains(@class, 'sidebar')]//dd[contains(@class, 'price-description')]"
  
  price.range.node <- tryCatch(html_node(htmlpage, xpath = xpath.expression),
                               error = function(err) {
                                 return(err)
                               })
  
  if (class(price.range.node)[1] == "xml_node") {
    
    price.range <- html_text(price.range.node)
    
    price.range <- gsub("[\f\n\r\t\v]", " ", price.range)
    price.range <- trimws(price.range, which = "both")
    
  } 
  
  # ------------------------------------------------------------
  # parse out the price range min and max
  # ------------------------------------------------------------
  
  price.range.min.and.max <- GetPriceRangeMinAndMax(price.range)
  
  # ------------------------------------------------------------
  # write data to .txt file
  # ------------------------------------------------------------
  
  new.record <- paste(business.id,
                      price.range.symbol,
                      price.range,
                      price.range.min.and.max[1],
                      price.range.min.and.max[2],
                      sep = "\t")
  
  write(new.record, file = BUSINESS_PRICE_RANGES_FILE, append = TRUE)
  
  # ------------------------------------------------------------
  # write data to .RData file
  # ------------------------------------------------------------
  
#   business.price.range.data <<- c(business.price.range.data, new.record)
#   save(business.price.range.data, file = BUSINESS_PRICE_RANGES_RDATA_FILE)
  
  # ------------------------------------------------------------
  
  return(0)
  
}   # end of function CollectPriceRangeData

# --------------------------------------------------------------

GetPriceRangeMinAndMax <- function(price.range) {
  
  # --------------------------------------------------
  #
  #  input:  price.range
  #
  #  Examples:  "$10-30"
  #             ""
  #             "Moderate"
  #             "Under $10"
  #
  # --------------------------------------------------
  
  # GetPriceRangeMinAndMax("$10-30 dollars - xyz")
  # GetPriceRangeMinAndMax("$10-30 dollars")
  # GetPriceRangeMinAndMax("yelp - price - categories")
  # GetPriceRangeMinAndMax("Up to $10")
  # GetPriceRangeMinAndMax("Moderate")
  
  range.parts <- strsplit(price.range, "-")[[1]]
  
  range.parts <- gsub("[^0-9]", "", range.parts)
  range.parts <- range.parts[nchar(range.parts) > 0]
  
  price.range.min.and.max <- c("", "")
  
  if (length(range.parts) > 1) {
    price.range.min.and.max <- range.parts[1:2]
  } else {
    if (length(range.parts) == 1) {
      price.range.min.and.max <- c("0", range.parts)
    } 
  }
  
  return(price.range.min.and.max)
  
}    # end of function GetPriceRangeMinAndMax




# --------------------------------------------------------------

processInputRecord <- function(input.record,htmlpage) {
  
  # go grab a web page
  
  # http GET!
  
  # business.id <- input.record[[1]][1]
  
  
  business.id <- input.record
  
  
  #   yelp.business.url <- paste0("http://www.yelp.com/biz/", business.id)
  
  #   cat("---------------------------------------\n")
  #   cat("Business Id: ", input.record[[1]][1], "\n")
  #   cat("yelp.business.url: ", yelp.business.url, "\n")
  #   cat("---------------------------------------\n")
  
  #   htmlpage <- read_html(yelp.business.url)
  
  
  # ------------------------------------------------------------
  # This should be the only place in the script that makes an 
  # http GET request to the Yelp website.
  #
  # Therefore, put a time delay at this point.
  #
  # Pause the program at this point.
  #
  # Randomly select the delay time to be 
  # between 3 to 10 seconds.
  # ------------------------------------------------------------
#   wait.time <- sample(3:10, 1)
#   Sys.sleep(wait.time)
#   
  
  # ---------------------------------------------
  
  day.and.hours.nodes <- html_nodes(htmlpage, xpath = "//table[contains(@class, 'hours-table')]/tbody/tr")
  
  
  if (length(day.and.hours.nodes) > 0) {
    for (i in 1:length(day.and.hours.nodes)) {
      processDayAndHoursNode(day.and.hours.nodes[[i]], business.id)
    }
  }
  else {
    cat("No business hours for: ", business.id, "\n")
  }
  
  # ---------------------------------------------
  
  processMoreBusinessInfo(htmlpage, business.id)
  
  # ---------------------------------------------
  
  CollectPriceRangeData(htmlpage, business.id)
  
  # ---------------------------------------------
  
  return(0)
  
}    # end of function processInputRecord()


# --------------------------------------------------------------






#---------------------------------
#     END OF Functions 
#---------------------------------



# getwd()




# ------------ Main Program -----------------------------

mainfunction <- function(dummy)
  
{
  
  
  restaurant.list <- read.delim(file = filename , sep = "\t", header = T,stringsAsFactors = F)
  
  # restaurant.list <- read.delim(file = "unique_bussinesses_seattle.txt", sep = "\t", header = T,stringsAsFactors = F)
  
  
  # restaurant.list <- read.delim(file = "businesses_sample_41.txt", sep = "\t", header = T,stringsAsFactors = F)
  
  
  rest.id <- restaurant.list$id
  rest.name <- restaurant.list$name
  rest.bus.url <- restaurant.list$url
  rest.review.count <- restaurant.list$review_count
  
  scriptInit()
  
  list.index <<- 0
  
  
  #--------------------------------------------
  # DELETE THE OUTPUT FILES IF EXISTS
  #--------------------------------------------
  
  unlink("TotalReviews")
  
  unlink("Totalreviews.RData")
  
  #--------------------------------------------
  # writes headers to the output file
  #--------------------------------------------
  
  write.header.to.file(dummy)
  
  #------------------------------------------------------------------------------------------
  # this for loop calls the function processReviewContainers passing the url of the webpage
  # this loop executes once for every single business id 
  # this loop executes as many times as the number of business ids in the input file 
  #------------------------------------------------------------------------------------------
  
  for(j in 1:length(rest.bus.url))
  {
    if(rest.name[j] != "")
    {
      remainder <- ""
      remainder <- rest.review.count[j] %% 20
      if(remainder == 0)
      {
        review.webpage.count <- ((rest.review.count[j] %/% 20))
      } else {
        review.webpage.count <- ((rest.review.count[j] %/% 20) + 1)
      }
      
      #-----------------------------------------------------------------------------------------
      # review.webpage.count has the count of the number of webpages a single business id has
      #-----------------------------------------------------------------------------------------
      
      website.split <- unlist(strsplit(rest.bus.url[j],split = "\\?"))
      
      htmlpage <- html(website.split[1])
#       n <- runif(1,2,4)
#       Sys.sleep(n)
      processInputRecord(rest.id[j],htmlpage)
      # --------------------------------------------------------------
      # a "review container" will contain 1 or more reviews
      # --------------------------------------------------------------
      review.containers <- html_nodes(htmlpage, xpath = "//ul[@class='ylist ylist-bordered reviews']/li/div[@data-review-id]")
      
      if(length(review.containers) == 0)
      {
        next
      }
      #   
      #     reviews <- processReviewContainers(review.containers,rest.id[j])
      
      list.index <- processReviewContainers(review.containers,rest.id[j],list.index)
      
      
      # -------------------------------------------------------
      
      
      if(review.webpage.count > 1)
      {  
        for(k in 2:review.webpage.count)
        {
          website.split[k] <- paste0(website.split[1],"?start=",((k - 1) * 20))
          
          htmlpage <- html(website.split[k])
#           n <- runif(1,2,4)
#           Sys.sleep(n)
          # --------------------------------------------------------------
          # a "review container" will contain 1 or more reviews
          # --------------------------------------------------------------
          review.containers <- html_nodes(htmlpage, xpath = "//ul[@class='ylist ylist-bordered reviews']/li/div[@data-review-id]")
          
          if(length(review.containers) == 0)
          {
            next
          }
          #         reviews <- processReviewContainers(review.containers,rest.id[j])
          
          list.index <- processReviewContainers(review.containers,rest.id[j],list.index)
          
          
          # -------------------------------------------------------
          
          
          
        }
      }
      
      # sys.sleep(.50)  
      
      
      
      # -----------------------------------------------------------------------------------
      
      # START OF THE PROGRAM TO FETCH NOT RECOMMENDED REVIEWS
      
      # -----------------------------------------------------------------------------------
      
      
      website.split <- unlist(strsplit(rest.bus.url[j],split = "\\?"))
      
      website.split.spam <- sub("biz","not_recommended_reviews",website.split[1])
      
      htmlpage.spam <- html(website.split.spam)
#       n <- runif(1,2,4)
#       Sys.sleep(n)
      
      review.spam.containers <- html_nodes(htmlpage.spam, xpath = "//div[@class='ysection not-recommended-reviews review-list-wide']//ul[@class='ylist ylist-bordered reviews']/li/div[@data-review-id]")
      
      review.spam.count.node <- html_nodes(htmlpage.spam, xpath = "//div[@class='ysection not-recommended-reviews review-list-wide']//h3")
      
      review.spam.count.t1 <- html_text(review.spam.count.node)
      
      review.spam.count.t2 <- gsub("\n"," ",review.spam.count.t1)
      
      pos.review.spam.count <- regexpr("review",review.spam.count.t2)
      
      review.spam.count <- as.integer(trimws(substr(review.spam.count.t2,1,(pos.review.spam.count - 1))))
      
      
      #   review.spam.webpage.count
      
      
      remainder.spam <- ""
      remainder.spam <- review.spam.count %% 10
      if(remainder.spam == 0)
      {
        review.spam.webpage.count <- ((review.spam.count %/% 10))
      } else {
        review.spam.webpage.count <- ((review.spam.count %/% 10) + 1)
      }
      
      # --------------------------------------------------------------
      # a "review container" will contain 1 or more reviews
      # --------------------------------------------------------------
      review.spam.containers <- html_nodes(htmlpage.spam, xpath = "//div[@class='ysection not-recommended-reviews review-list-wide']//ul[@class='ylist ylist-bordered reviews']/li/div[@data-review-id]")
      
      if(length(review.spam.containers) == 0)
      {
        next
      }
      #   
      #     reviews <- processSpamReviewContainers(review.spam.containers,rest.id[j])
      
      list.index <- processSpamReviewContainers(review.spam.containers,rest.id[j],list.index)
      
      
      # -------------------------------------------------------
      if(review.spam.webpage.count > 1)
      {  
        for(n in 2:review.spam.webpage.count)
        {
          website.split.spam[n] <- paste0(website.split.spam,"?not_recommended_start=",((n - 1) * 10))
          
          htmlpage.spam <- html(website.split.spam[n])
#           n <- runif(1,2,4)
#           Sys.sleep(n)
          
          
          # --------------------------------------------------------------
          # a "review container" will contain 1 or more reviews
          # --------------------------------------------------------------
          review.spam.containers <- html_nodes(htmlpage.spam, xpath = "//div[@class='ysection not-recommended-reviews review-list-wide']//ul[@class='ylist ylist-bordered reviews']/li/div[@data-review-id]")
          
          if(length(review.spam.containers) == 0)
          {
            next
          }
          #         reviews <- processSpamReviewContainers(review.spam.containers,rest.id[j])
          
          list.index <- processSpamReviewContainers(review.spam.containers,rest.id[j],list.index)
          
          
          # -------------------------------------------------------
          
          
          
        }
      }
      
      
      
      #     Sys.sleep(10)
      
      
#       n <- runif(1,2,4)
#       Sys.sleep(n)
      print(paste0("Iterator: number of restaurant = ",j))
      print(paste0("Iterator: number of reviews = ",list.index))
      
      
      
    }
    
    
  }   # End of main for loop
  
  
  
  detach("package:rvest", unload = TRUE)
  detach("package:XML", unload = TRUE)
  
  
}  # End of main function 


#------------------------------------------------------

# ------------------
# Main Program  
# ------------------

# source("Build_Business_Master_List.R")

mainfunction(dummy)

